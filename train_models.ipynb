{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2982d727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in .\\venv\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in .\\venv\\lib\\site-packages (from openpyxl) (2.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install scikit-learn\n",
    "# !pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f026f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7c64dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the models directory exists\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f212d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess your data\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load and preprocess the work utilization data\"\"\"\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Clean column names (remove whitespace)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    # Ensure Date column is datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Ensure WorkType is treated as string\n",
    "    df['WorkType'] = df['WorkType'].astype(str)\n",
    "    \n",
    "    # Fix Hours and NoOfMan columns - replace \"-\" with 0 and convert to numeric\n",
    "    if 'Hours' in df.columns:\n",
    "        df['Hours'] = df['Hours'].replace('-', 0)\n",
    "        df['Hours'] = pd.to_numeric(df['Hours'], errors='coerce').fillna(0)\n",
    "        \n",
    "    if 'NoOfMan' in df.columns:\n",
    "        df['NoOfMan'] = df['NoOfMan'].replace('-', 0)\n",
    "        df['NoOfMan'] = pd.to_numeric(df['NoOfMan'], errors='coerce').fillna(0)\n",
    "    \n",
    "    # Sort by Date\n",
    "    df = df.sort_values('Date')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Feature engineering function\n",
    "def engineer_features(df):\n",
    "    \"\"\"Create relevant features for the prediction model\"\"\"\n",
    "    # Create a copy to avoid modifying the original dataframe\n",
    "    data = df.copy()\n",
    "    \n",
    "    # Extract date features\n",
    "    data['Year_feat'] = data['Date'].dt.year\n",
    "    data['Month_feat'] = data['Date'].dt.month\n",
    "    data['DayOfMonth'] = data['Date'].dt.day\n",
    "    data['DayOfWeek_feat'] = data['Date'].dt.dayofweek  # 0=Monday, 6=Sunday\n",
    "    data['Quarter'] = data['Date'].dt.quarter\n",
    "    data['IsWeekend_feat'] = data['DayOfWeek_feat'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    \n",
    "    # Add week of year\n",
    "    data['WeekOfYear'] = data['Date'].dt.isocalendar().week\n",
    "    \n",
    "    # Add day of year\n",
    "    data['DayOfYear'] = data['Date'].dt.dayofyear\n",
    "    \n",
    "    # Calculate days since the start of the dataset\n",
    "    min_date = data['Date'].min()\n",
    "    data['DaysSinceStart'] = (data['Date'] - min_date).dt.days\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def create_lag_features(data, group_col='WorkType', target_col='NoOfMan', lag_days=[1, 2, 3, 7, 14, 30]):\n",
    "    \"\"\"Create lag features for each WorkType's NoOfMan value\"\"\"\n",
    "    # Make a copy of the input dataframe\n",
    "    data_copy = data.copy()\n",
    "    \n",
    "    # First, check if there are any non-zero values in the target column\n",
    "    non_zero_count = (data_copy[target_col] > 0).sum()\n",
    "    print(f\"Number of non-zero {target_col} values: {non_zero_count} out of {len(data_copy)}\")\n",
    "    \n",
    "    # # Group by WorkType and Date to get daily aggregates\n",
    "    \n",
    "    # Use date only if Date contains time information\n",
    "    # if pd.api.types.is_datetime64_dtype(data_copy['Date']):\n",
    "    #     data_copy['Date_day'] = data_copy['Date'].dt.date\n",
    "    #     daily_data = data_copy.groupby([group_col, 'Date_day'])[target_col].sum().reset_index()\n",
    "    #     daily_data['Date'] = pd.to_datetime(daily_data['Date_day'])\n",
    "    #     daily_data = daily_data.drop('Date_day', axis=1)\n",
    "    #     print('If')\n",
    "    # else:\n",
    "    #     daily_data = data_copy.groupby([group_col, 'Date'])[target_col].sum().reset_index()\n",
    "    #     print('Else')\n",
    "    \n",
    "    # Add the engineered features we need\n",
    "    # daily_data['DayOfWeek_feat'] = daily_data['Date'].dt.dayofweek\n",
    "    # daily_data['Month_feat'] = daily_data['Date'].dt.month\n",
    "    # daily_data['IsWeekend_feat'] = daily_data['DayOfWeek_feat'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "    # daily_data['Year_feat'] = daily_data['Date'].dt.year\n",
    "    # daily_data['Quarter'] = daily_data['Date'].dt.quarter\n",
    "    # daily_data['DayOfMonth'] = daily_data['Date'].dt.day\n",
    "    \n",
    "    # # Ensure data is properly sorted by WorkType and Date (critical for time-series operations)\n",
    "    daily_data = data_copy.sort_values([group_col, 'Date'])\n",
    "    \n",
    "    # Create lag features for each work type\n",
    "    for lag in lag_days:\n",
    "        daily_data[f'{target_col}_lag_{lag}'] = daily_data.groupby(group_col)[target_col].shift(lag)\n",
    "    \n",
    "    # Create rolling features by work type\n",
    "    for work_type in daily_data[group_col].unique():\n",
    "        mask = daily_data[group_col] == work_type\n",
    "        work_type_data = daily_data.loc[mask, target_col]\n",
    "        \n",
    "        if len(work_type_data) >= 1:\n",
    "            daily_data.loc[mask, f'{target_col}_rolling_mean_7'] = work_type_data.rolling(\n",
    "                window=7, min_periods=1).mean()\n",
    "            daily_data.loc[mask, f'{target_col}_rolling_max_7'] = work_type_data.rolling(\n",
    "                window=7, min_periods=1).max()\n",
    "            daily_data.loc[mask, f'{target_col}_rolling_min_7'] = work_type_data.rolling(\n",
    "                window=7, min_periods=1).min()\n",
    "            daily_data.loc[mask, f'{target_col}_rolling_std_7'] = work_type_data.rolling(\n",
    "                window=7, min_periods=1).std().fillna(0)\n",
    "    \n",
    "    # Create same day of week lag\n",
    "    daily_data[f'{target_col}_same_dow_lag'] = daily_data.groupby([group_col, 'DayOfWeek_feat'])[target_col].shift(1)\n",
    "    \n",
    "    # Instead of dropping NaN values, fill with 0\n",
    "    # This is crucial because dropping rows with NaN values might eliminate too much data\n",
    "    daily_data = daily_data.fillna(0)\n",
    "    return daily_data\n",
    "\n",
    "# Build and train model for each WorkType\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def build_models(processed_data, work_types, n_splits=5):\n",
    "    \"\"\"Build and train a model for each WorkType using time series cross-validation\"\"\"\n",
    "    models = {}\n",
    "    feature_importances = {}\n",
    "    metrics = {}\n",
    "    \n",
    "    # Define features to use\n",
    "    numeric_features = [\n",
    "        'NoOfMan_lag_1', 'NoOfMan_lag_2', 'NoOfMan_lag_3', 'NoOfMan_lag_7', \n",
    "        'NoOfMan_lag_14', 'NoOfMan_lag_30', 'NoOfMan_rolling_mean_7',\n",
    "        'NoOfMan_rolling_max_7', 'NoOfMan_rolling_min_7', 'NoOfMan_rolling_std_7',\n",
    "        'NoOfMan_same_dow_lag', 'IsWeekend_feat'\n",
    "    ]\n",
    "    \n",
    "    categorical_features = ['DayOfWeek_feat', 'Month_feat']\n",
    "    \n",
    "    # Function to calculate modified MAPE with minimum threshold\n",
    "    def modified_mape(y_true, y_pred, epsilon=1.0):\n",
    "        \"\"\"Calculate MAPE with a minimum threshold to avoid division by zero\"\"\"\n",
    "        # Use max of actual value or epsilon (e.g., 1.0) as denominator\n",
    "        denominator = np.maximum(np.abs(y_true), epsilon)\n",
    "        return np.mean(np.abs(y_pred - y_true) / denominator) * 100\n",
    "    \n",
    "    for work_type in work_types:\n",
    "        print(f\"Building model for WorkType: {work_type}\")\n",
    "        \n",
    "        # Filter data for this WorkType\n",
    "        work_type_data = processed_data[processed_data['WorkType'] == work_type]\n",
    "        \n",
    "        if len(work_type_data) < 30:  # Skip if not enough data\n",
    "            print(f\"  Skipping {work_type}: Not enough data ({len(work_type_data)} records)\")\n",
    "            continue\n",
    "        \n",
    "        # Sort data by date to ensure time-based splitting works correctly\n",
    "        work_type_data = work_type_data.sort_values('Date')\n",
    "        \n",
    "        # Prepare features and target\n",
    "        X = work_type_data[numeric_features + categorical_features]\n",
    "        y = work_type_data['NoOfMan']\n",
    "        \n",
    "        # Define preprocessing for categorical features\n",
    "        preprocessor = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "        \n",
    "        # Define the model pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "        ])\n",
    "        \n",
    "        # Initialize TimeSeriesSplit with n splits\n",
    "        tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "        \n",
    "        # Initialize metrics lists\n",
    "        mae_scores = []\n",
    "        rmse_scores = []\n",
    "        r2_scores = []\n",
    "        mape_scores = []\n",
    "        \n",
    "        # Perform time series cross-validation\n",
    "        for train_idx, test_idx in tscv.split(X):\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "            \n",
    "            # Train model\n",
    "            pipeline.fit(X_train, y_train)\n",
    "            \n",
    "            # Make predictions\n",
    "            y_pred = pipeline.predict(X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mae_scores.append(mean_absolute_error(y_test, y_pred))\n",
    "            rmse_scores.append(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "            r2_scores.append(r2_score(y_test, y_pred))\n",
    "            \n",
    "            # Calculate modified MAPE\n",
    "            mape = modified_mape(y_test, y_pred, epsilon=1.0)\n",
    "            mape_scores.append(mape)\n",
    "        \n",
    "        # Train final model on all data\n",
    "        pipeline.fit(X, y)\n",
    "        models[work_type] = pipeline\n",
    "        \n",
    "        # Get feature importances from the final model\n",
    "        model = pipeline.named_steps['model']\n",
    "        ohe = pipeline.named_steps['preprocessor'].transformers_[0][1]\n",
    "        \n",
    "        # Extract feature names after one-hot encoding\n",
    "        cat_feature_names = []\n",
    "        for i, feature in enumerate(categorical_features):\n",
    "            categories = ohe.categories_[i]\n",
    "            for category in categories:\n",
    "                cat_feature_names.append(f\"{feature}_{category}\")\n",
    "        \n",
    "        # Combine with numeric feature names\n",
    "        all_feature_names = cat_feature_names + numeric_features\n",
    "        \n",
    "        # Get feature importances\n",
    "        importances = model.feature_importances_\n",
    "        \n",
    "        # Create dictionary of feature importances\n",
    "        feature_importances[work_type] = dict(zip(all_feature_names, importances))\n",
    "        \n",
    "        # Store average metrics\n",
    "        metrics[work_type] = {\n",
    "            'MAE': np.mean(mae_scores),\n",
    "            'RMSE': np.mean(rmse_scores),\n",
    "            'R²': np.mean(r2_scores),\n",
    "            'MAPE': np.mean(mape_scores)\n",
    "        }\n",
    "        \n",
    "        print(f\"  Model for {work_type} - MAE: {metrics[work_type]['MAE']:.4f}, RMSE: {metrics[work_type]['RMSE']:.4f}, R²: {metrics[work_type]['R²']:.4f}, MAPE: {metrics[work_type]['MAPE']:.2f}%\")\n",
    "        \n",
    "        # Also print individual fold scores for detailed analysis\n",
    "        print(f\"  Cross-validation details:\")\n",
    "        for i in range(len(mae_scores)):\n",
    "            print(f\"    Fold {i+1}: MAE={mae_scores[i]:.4f}, RMSE={rmse_scores[i]:.4f}, R²={r2_scores[i]:.4f}, MAPE={mape_scores[i]:.2f}%\")\n",
    "    \n",
    "    return models, feature_importances, metrics\n",
    "\n",
    "\n",
    "\n",
    "# def build_models(processed_data, work_types):\n",
    "#     \"\"\"Build and train a model for each WorkType\"\"\"\n",
    "#     models = {}\n",
    "#     feature_importances = {}\n",
    "#     metrics = {}\n",
    "    \n",
    "#     # Define features to use\n",
    "#     numeric_features = [\n",
    "#         'NoOfMan_lag_1', 'NoOfMan_lag_2', 'NoOfMan_lag_3', 'NoOfMan_lag_7', \n",
    "#         'NoOfMan_lag_14', 'NoOfMan_lag_30', 'NoOfMan_rolling_mean_7',\n",
    "#         'NoOfMan_rolling_max_7', 'NoOfMan_rolling_min_7', 'NoOfMan_rolling_std_7',\n",
    "#         'NoOfMan_same_dow_lag', 'IsWeekend_feat'\n",
    "#     ]\n",
    "    \n",
    "#     categorical_features = ['DayOfWeek_feat', 'Month_feat']\n",
    "    \n",
    "#     for work_type in work_types:\n",
    "#         print(f\"Building model for WorkType: {work_type}\")\n",
    "        \n",
    "#         # Filter data for this WorkType\n",
    "#         work_type_data = processed_data[processed_data['WorkType'] == work_type]\n",
    "        \n",
    "#         if len(work_type_data) < 30:  # Skip if not enough data\n",
    "#             print(f\"  Skipping {work_type}: Not enough data ({len(work_type_data)} records)\")\n",
    "#             continue\n",
    "            \n",
    "#         # Split into train and test (use most recent 30 days as test)\n",
    "#         train_data = work_type_data[work_type_data['Date'] < work_type_data['Date'].max() - timedelta(days=30)]\n",
    "#         test_data = work_type_data[work_type_data['Date'] >= work_type_data['Date'].max() - timedelta(days=30)]\n",
    "        \n",
    "#         if len(train_data) < 30 or len(test_data) < 7:  # Skip if not enough data for training or testing\n",
    "#             print(f\"  Skipping {work_type}: Not enough data for train/test split\")\n",
    "#             continue\n",
    "        \n",
    "#         # Prepare features and target\n",
    "#         X_train = train_data[numeric_features + categorical_features]\n",
    "#         y_train = train_data['NoOfMan']\n",
    "        \n",
    "#         X_test = test_data[numeric_features + categorical_features]\n",
    "#         y_test = test_data['NoOfMan']\n",
    "        \n",
    "#         # Define preprocessing for categorical features\n",
    "#         preprocessor = ColumnTransformer(\n",
    "#             transformers=[\n",
    "#                 ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "#             ],\n",
    "#             remainder='passthrough'\n",
    "#         )\n",
    "        \n",
    "#         # Define the model pipeline\n",
    "#         pipeline = Pipeline([\n",
    "#             ('preprocessor', preprocessor),\n",
    "#             ('model', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "#         ])\n",
    "        \n",
    "#         # Train the model\n",
    "#         pipeline.fit(X_train, y_train)\n",
    "        \n",
    "#         # Save the model\n",
    "#         models[work_type] = pipeline\n",
    "        \n",
    "#         # Get feature importances\n",
    "#         model = pipeline.named_steps['model']\n",
    "#         ohe = pipeline.named_steps['preprocessor'].transformers_[0][1]\n",
    "        \n",
    "#         # Extract feature names after one-hot encoding\n",
    "#         cat_feature_names = []\n",
    "#         for i, feature in enumerate(categorical_features):\n",
    "#             categories = ohe.categories_[i]\n",
    "#             for category in categories:\n",
    "#                 cat_feature_names.append(f\"{feature}_{category}\")\n",
    "        \n",
    "#         # Combine with numeric feature names\n",
    "#         all_feature_names = cat_feature_names + numeric_features\n",
    "        \n",
    "#         # Get feature importances\n",
    "#         importances = model.feature_importances_\n",
    "        \n",
    "#         # Create dictionary of feature importances\n",
    "#         feature_importances[work_type] = dict(zip(all_feature_names, importances))\n",
    "        \n",
    "#         # Evaluate on test data\n",
    "#         y_pred = pipeline.predict(X_test)\n",
    "        \n",
    "#         # Calculate metrics\n",
    "#         mae = mean_absolute_error(y_test, y_pred)\n",
    "#         rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "#         # Calculate MAPE (Mean Absolute Percentage Error)\n",
    "#         # Handle zero values in y_true to avoid division by zero\n",
    "#         y_true_nonzero = np.array([max(0.0001, y) for y in y_test])\n",
    "#         mape = np.mean(np.abs((y_true_nonzero - y_pred) / y_true_nonzero)) * 100\n",
    "        \n",
    "#         metrics[work_type] = {\n",
    "#             'MAE': mae,\n",
    "#             'RMSE': rmse,\n",
    "#             'R²': r2,\n",
    "#             'MAPE': mape\n",
    "#         }\n",
    "        \n",
    "#         print(f\"  Model for {work_type} - MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}, MAPE: {mape:.2f}%\")\n",
    "    \n",
    "#     return models, feature_importances, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1b9a7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>DayOfweek</th>\n",
       "      <th>WorkType</th>\n",
       "      <th>Hours</th>\n",
       "      <th>NoOfMan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>201</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>222 Storage optimization</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>221 Stocktaking</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>217 Returns</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>215 Picking Online</td>\n",
       "      <td>67.15</td>\n",
       "      <td>8.39375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Month  Week  Day       Date DayOfweek                  WorkType  \\\n",
       "0   2017      1     1    2 2017-01-02    Monday                       201   \n",
       "24  2017      1     1    2 2017-01-02    Monday  222 Storage optimization   \n",
       "23  2017      1     1    2 2017-01-02    Monday           221 Stocktaking   \n",
       "22  2017      1     1    2 2017-01-02    Monday               217 Returns   \n",
       "21  2017      1     1    2 2017-01-02    Monday        215 Picking Online   \n",
       "\n",
       "    Hours  NoOfMan  \n",
       "0    0.00  0.00000  \n",
       "24   0.00  0.00000  \n",
       "23   0.00  0.00000  \n",
       "22   0.00  0.00000  \n",
       "21  67.15  8.39375  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = \"C:/forlogssystems/Data/work_utilization_melted.xlsx\"\n",
    "df = load_data(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1294ed6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>DayOfweek</th>\n",
       "      <th>WorkType</th>\n",
       "      <th>Hours</th>\n",
       "      <th>NoOfMan</th>\n",
       "      <th>Year_feat</th>\n",
       "      <th>Month_feat</th>\n",
       "      <th>DayOfMonth</th>\n",
       "      <th>DayOfWeek_feat</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>IsWeekend_feat</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>DayOfYear</th>\n",
       "      <th>DaysSinceStart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>201</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>222 Storage optimization</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>221 Stocktaking</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>217 Returns</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>215 Picking Online</td>\n",
       "      <td>67.15</td>\n",
       "      <td>8.39375</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>214 Large orders</td>\n",
       "      <td>19.65</td>\n",
       "      <td>2.45625</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>213 Pick3PL_Astro</td>\n",
       "      <td>34.00</td>\n",
       "      <td>4.25000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>210 Pick Sortation</td>\n",
       "      <td>48.57</td>\n",
       "      <td>6.07125</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>209 Sortation</td>\n",
       "      <td>64.79</td>\n",
       "      <td>8.09875</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>208 Sorter 2 SALE</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Month  Week  Day       Date DayOfweek                  WorkType  \\\n",
       "0   2017      1     1    2 2017-01-02    Monday                       201   \n",
       "24  2017      1     1    2 2017-01-02    Monday  222 Storage optimization   \n",
       "23  2017      1     1    2 2017-01-02    Monday           221 Stocktaking   \n",
       "22  2017      1     1    2 2017-01-02    Monday               217 Returns   \n",
       "21  2017      1     1    2 2017-01-02    Monday        215 Picking Online   \n",
       "20  2017      1     1    2 2017-01-02    Monday          214 Large orders   \n",
       "19  2017      1     1    2 2017-01-02    Monday         213 Pick3PL_Astro   \n",
       "17  2017      1     1    2 2017-01-02    Monday        210 Pick Sortation   \n",
       "16  2017      1     1    2 2017-01-02    Monday             209 Sortation   \n",
       "15  2017      1     1    2 2017-01-02    Monday         208 Sorter 2 SALE   \n",
       "\n",
       "    Hours  NoOfMan  Year_feat  Month_feat  DayOfMonth  DayOfWeek_feat  \\\n",
       "0    0.00  0.00000       2017           1           2               0   \n",
       "24   0.00  0.00000       2017           1           2               0   \n",
       "23   0.00  0.00000       2017           1           2               0   \n",
       "22   0.00  0.00000       2017           1           2               0   \n",
       "21  67.15  8.39375       2017           1           2               0   \n",
       "20  19.65  2.45625       2017           1           2               0   \n",
       "19  34.00  4.25000       2017           1           2               0   \n",
       "17  48.57  6.07125       2017           1           2               0   \n",
       "16  64.79  8.09875       2017           1           2               0   \n",
       "15   0.00  0.00000       2017           1           2               0   \n",
       "\n",
       "    Quarter  IsWeekend_feat  WeekOfYear  DayOfYear  DaysSinceStart  \n",
       "0         1               0           1          2               0  \n",
       "24        1               0           1          2               0  \n",
       "23        1               0           1          2               0  \n",
       "22        1               0           1          2               0  \n",
       "21        1               0           1          2               0  \n",
       "20        1               0           1          2               0  \n",
       "19        1               0           1          2               0  \n",
       "17        1               0           1          2               0  \n",
       "16        1               0           1          2               0  \n",
       "15        1               0           1          2               0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show all rows and columns without truncation\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', None)  # Expand display width\n",
    "pd.set_option('display.max_colwidth', None)  # Show full content of cells\n",
    "\n",
    "feature_df = engineer_features(df)\n",
    "feature_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64012d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero NoOfMan values: 30538 out of 73025\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>Date</th>\n",
       "      <th>DayOfweek</th>\n",
       "      <th>WorkType</th>\n",
       "      <th>Hours</th>\n",
       "      <th>NoOfMan</th>\n",
       "      <th>Year_feat</th>\n",
       "      <th>Month_feat</th>\n",
       "      <th>DayOfMonth</th>\n",
       "      <th>DayOfWeek_feat</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>IsWeekend_feat</th>\n",
       "      <th>WeekOfYear</th>\n",
       "      <th>DayOfYear</th>\n",
       "      <th>DaysSinceStart</th>\n",
       "      <th>NoOfMan_lag_1</th>\n",
       "      <th>NoOfMan_lag_2</th>\n",
       "      <th>NoOfMan_lag_3</th>\n",
       "      <th>NoOfMan_lag_7</th>\n",
       "      <th>NoOfMan_lag_14</th>\n",
       "      <th>NoOfMan_lag_30</th>\n",
       "      <th>NoOfMan_rolling_mean_7</th>\n",
       "      <th>NoOfMan_rolling_max_7</th>\n",
       "      <th>NoOfMan_rolling_min_7</th>\n",
       "      <th>NoOfMan_rolling_std_7</th>\n",
       "      <th>NoOfMan_same_dow_lag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2017-01-02</td>\n",
       "      <td>Monday</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>Friday</td>\n",
       "      <td>201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Month  Week  Day       Date  DayOfweek WorkType  Hours  NoOfMan  \\\n",
       "0    2017      1     1    2 2017-01-02     Monday      201    0.0      0.0   \n",
       "25   2017      1     1    3 2017-01-03    Tuesday      201    0.0      0.0   \n",
       "50   2017      1     1    4 2017-01-04  Wednesday      201    0.0      0.0   \n",
       "75   2017      1     1    5 2017-01-05   Thursday      201    0.0      0.0   \n",
       "100  2017      1     1    6 2017-01-06     Friday      201    0.0      0.0   \n",
       "\n",
       "     Year_feat  Month_feat  DayOfMonth  DayOfWeek_feat  Quarter  \\\n",
       "0         2017           1           2               0        1   \n",
       "25        2017           1           3               1        1   \n",
       "50        2017           1           4               2        1   \n",
       "75        2017           1           5               3        1   \n",
       "100       2017           1           6               4        1   \n",
       "\n",
       "     IsWeekend_feat  WeekOfYear  DayOfYear  DaysSinceStart  NoOfMan_lag_1  \\\n",
       "0                 0           1          2               0            0.0   \n",
       "25                0           1          3               1            0.0   \n",
       "50                0           1          4               2            0.0   \n",
       "75                0           1          5               3            0.0   \n",
       "100               0           1          6               4            0.0   \n",
       "\n",
       "     NoOfMan_lag_2  NoOfMan_lag_3  NoOfMan_lag_7  NoOfMan_lag_14  \\\n",
       "0              0.0            0.0            0.0             0.0   \n",
       "25             0.0            0.0            0.0             0.0   \n",
       "50             0.0            0.0            0.0             0.0   \n",
       "75             0.0            0.0            0.0             0.0   \n",
       "100            0.0            0.0            0.0             0.0   \n",
       "\n",
       "     NoOfMan_lag_30  NoOfMan_rolling_mean_7  NoOfMan_rolling_max_7  \\\n",
       "0               0.0                     0.0                    0.0   \n",
       "25              0.0                     0.0                    0.0   \n",
       "50              0.0                     0.0                    0.0   \n",
       "75              0.0                     0.0                    0.0   \n",
       "100             0.0                     0.0                    0.0   \n",
       "\n",
       "     NoOfMan_rolling_min_7  NoOfMan_rolling_std_7  NoOfMan_same_dow_lag  \n",
       "0                      0.0                    0.0                   0.0  \n",
       "25                     0.0                    0.0                   0.0  \n",
       "50                     0.0                    0.0                   0.0  \n",
       "75                     0.0                    0.0                   0.0  \n",
       "100                    0.0                    0.0                   0.0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_features_df = create_lag_features(feature_df)\n",
    "lag_features_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7f24cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model for WorkType: 201\n",
      "  Model for 201 - MAE: 0.2459, RMSE: 0.5261, R²: 0.7098, MAPE: 15.27%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.1999, RMSE=0.6082, R²=0.4780, MAPE=8.68%\n",
      "    Fold 2: MAE=0.4101, RMSE=0.6330, R²=0.7707, MAPE=26.54%\n",
      "    Fold 3: MAE=0.1237, RMSE=0.2663, R²=0.8275, MAPE=10.35%\n",
      "    Fold 4: MAE=0.1236, RMSE=0.3748, R²=0.7276, MAPE=8.62%\n",
      "    Fold 5: MAE=0.3721, RMSE=0.7481, R²=0.7450, MAPE=22.17%\n",
      "Building model for WorkType: 202 Goods receive G\n",
      "  Model for 202 Goods receive G - MAE: 0.3158, RMSE: 0.5102, R²: 0.7643, MAPE: 18.94%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.2677, RMSE=0.4276, R²=0.7398, MAPE=18.56%\n",
      "    Fold 2: MAE=0.2549, RMSE=0.4444, R²=0.7582, MAPE=17.22%\n",
      "    Fold 3: MAE=0.2606, RMSE=0.4304, R²=0.8126, MAPE=17.02%\n",
      "    Fold 4: MAE=0.3703, RMSE=0.5966, R²=0.7273, MAPE=21.49%\n",
      "    Fold 5: MAE=0.4256, RMSE=0.6521, R²=0.7836, MAPE=20.41%\n",
      "Building model for WorkType: 203 Goods receive D\n",
      "  Model for 203 Goods receive D - MAE: 0.5939, RMSE: 1.0012, R²: 0.8392, MAPE: 20.60%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.5750, RMSE=0.9788, R²=0.7930, MAPE=22.32%\n",
      "    Fold 2: MAE=0.7075, RMSE=1.1660, R²=0.8206, MAPE=24.64%\n",
      "    Fold 3: MAE=0.5260, RMSE=0.8625, R²=0.8881, MAPE=16.21%\n",
      "    Fold 4: MAE=0.6499, RMSE=1.1422, R²=0.8139, MAPE=21.18%\n",
      "    Fold 5: MAE=0.5110, RMSE=0.8564, R²=0.8802, MAPE=18.64%\n",
      "Building model for WorkType: 204\n",
      "  Model for 204 - MAE: 0.0045, RMSE: 0.0371, R²: 0.0694, MAPE: 0.44%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.0080, RMSE=0.0805, R²=-0.0224, MAPE=0.79%\n",
      "    Fold 2: MAE=0.0133, RMSE=0.0890, R²=-0.0515, MAPE=1.30%\n",
      "    Fold 3: MAE=0.0000, RMSE=0.0001, R²=-0.0021, MAPE=0.00%\n",
      "    Fold 4: MAE=0.0010, RMSE=0.0116, R²=-0.1476, MAPE=0.10%\n",
      "    Fold 5: MAE=0.0004, RMSE=0.0044, R²=0.5708, MAPE=0.04%\n",
      "Building model for WorkType: 205\n",
      "  Model for 205 - MAE: 0.0017, RMSE: 0.0223, R²: 0.1635, MAPE: 0.17%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.0015, RMSE=0.0323, R²=-0.0021, MAPE=0.15%\n",
      "    Fold 2: MAE=0.0000, RMSE=0.0004, R²=-0.0021, MAPE=0.00%\n",
      "    Fold 3: MAE=0.0003, RMSE=0.0070, R²=0.0567, MAPE=0.03%\n",
      "    Fold 4: MAE=0.0000, RMSE=0.0000, R²=1.0000, MAPE=0.00%\n",
      "    Fold 5: MAE=0.0069, RMSE=0.0716, R²=-0.2349, MAPE=0.69%\n",
      "Building model for WorkType: 206 Replenishment\n",
      "  Model for 206 Replenishment - MAE: 2.0577, RMSE: 3.4071, R²: 0.9057, MAPE: 35.72%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=2.2379, RMSE=3.7550, R²=0.8902, MAPE=39.93%\n",
      "    Fold 2: MAE=2.2731, RMSE=3.9861, R²=0.8922, MAPE=45.83%\n",
      "    Fold 3: MAE=1.9399, RMSE=3.0166, R²=0.9185, MAPE=27.78%\n",
      "    Fold 4: MAE=1.8817, RMSE=3.0987, R²=0.9103, MAPE=27.80%\n",
      "    Fold 5: MAE=1.9557, RMSE=3.1793, R²=0.9175, MAPE=37.24%\n",
      "Building model for WorkType: 207 Fair\n",
      "  Model for 207 Fair - MAE: 0.2250, RMSE: 0.6971, R²: 0.4909, MAPE: 11.70%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.3906, RMSE=1.0107, R²=0.5363, MAPE=23.51%\n",
      "    Fold 2: MAE=0.0878, RMSE=0.4250, R²=0.8165, MAPE=4.75%\n",
      "    Fold 3: MAE=0.0036, RMSE=0.0511, R²=-0.2730, MAPE=0.36%\n",
      "    Fold 4: MAE=0.3326, RMSE=1.0343, R²=0.6695, MAPE=16.82%\n",
      "    Fold 5: MAE=0.3105, RMSE=0.9644, R²=0.7050, MAPE=13.08%\n",
      "Building model for WorkType: 208 Sorter 2 SALE\n",
      "  Model for 208 Sorter 2 SALE - MAE: 1.3265, RMSE: 3.1675, R²: 0.7288, MAPE: 49.94%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=1.3309, RMSE=3.5123, R²=0.6824, MAPE=52.44%\n",
      "    Fold 2: MAE=1.8398, RMSE=4.2030, R²=0.6829, MAPE=73.62%\n",
      "    Fold 3: MAE=1.2034, RMSE=2.9136, R²=0.7554, MAPE=43.18%\n",
      "    Fold 4: MAE=0.7579, RMSE=2.1921, R²=0.8313, MAPE=24.12%\n",
      "    Fold 5: MAE=1.5007, RMSE=3.0163, R²=0.6921, MAPE=56.35%\n",
      "Building model for WorkType: 209 Sortation\n",
      "  Model for 209 Sortation - MAE: 1.4962, RMSE: 2.5567, R²: 0.7957, MAPE: 35.20%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=1.8875, RMSE=3.2258, R²=0.7400, MAPE=39.69%\n",
      "    Fold 2: MAE=1.6661, RMSE=2.9608, R²=0.7527, MAPE=46.46%\n",
      "    Fold 3: MAE=1.3318, RMSE=2.2258, R²=0.7942, MAPE=30.24%\n",
      "    Fold 4: MAE=1.1175, RMSE=1.7755, R²=0.8605, MAPE=27.76%\n",
      "    Fold 5: MAE=1.4781, RMSE=2.5956, R²=0.8311, MAPE=31.86%\n",
      "Building model for WorkType: 210 Pick Sortation\n",
      "  Model for 210 Pick Sortation - MAE: 1.0436, RMSE: 1.7937, R²: 0.8372, MAPE: 27.82%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.9941, RMSE=1.6905, R²=0.8155, MAPE=28.75%\n",
      "    Fold 2: MAE=1.2604, RMSE=2.2580, R²=0.7913, MAPE=32.90%\n",
      "    Fold 3: MAE=0.8178, RMSE=1.3853, R²=0.8700, MAPE=19.73%\n",
      "    Fold 4: MAE=0.8643, RMSE=1.4715, R²=0.8887, MAPE=22.78%\n",
      "    Fold 5: MAE=1.2813, RMSE=2.1630, R²=0.8204, MAPE=34.93%\n",
      "Building model for WorkType: 211 Misc\n",
      "  Model for 211 Misc - MAE: 1.3720, RMSE: 2.2096, R²: 0.8422, MAPE: 34.11%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=1.7787, RMSE=2.9870, R²=0.7833, MAPE=44.63%\n",
      "    Fold 2: MAE=1.8305, RMSE=2.9708, R²=0.7694, MAPE=42.88%\n",
      "    Fold 3: MAE=1.0965, RMSE=1.6971, R²=0.8909, MAPE=24.92%\n",
      "    Fold 4: MAE=1.1092, RMSE=1.7733, R²=0.8788, MAPE=30.07%\n",
      "    Fold 5: MAE=1.0450, RMSE=1.6199, R²=0.8888, MAPE=28.05%\n",
      "Building model for WorkType: 212\n",
      "  Model for 212 - MAE: 0.0019, RMSE: 0.0251, R²: 0.1070, MAPE: 0.19%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.0004, RMSE=0.0075, R²=-0.0022, MAPE=0.04%\n",
      "    Fold 2: MAE=0.0019, RMSE=0.0411, R²=0.1788, MAPE=0.19%\n",
      "    Fold 3: MAE=0.0000, RMSE=0.0000, R²=1.0000, MAPE=0.00%\n",
      "    Fold 4: MAE=0.0036, RMSE=0.0507, R²=-0.5339, MAPE=0.36%\n",
      "    Fold 5: MAE=0.0037, RMSE=0.0261, R²=-0.1077, MAPE=0.37%\n",
      "Building model for WorkType: 213 Pick3PL_Astro\n",
      "  Model for 213 Pick3PL_Astro - MAE: 0.6086, RMSE: 0.9816, R²: 0.7810, MAPE: 27.16%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.6976, RMSE=1.1429, R²=0.7573, MAPE=28.08%\n",
      "    Fold 2: MAE=0.5711, RMSE=0.8989, R²=0.8539, MAPE=22.78%\n",
      "    Fold 3: MAE=0.6080, RMSE=1.0068, R²=0.7365, MAPE=29.70%\n",
      "    Fold 4: MAE=0.5539, RMSE=0.9037, R²=0.7739, MAPE=28.05%\n",
      "    Fold 5: MAE=0.6126, RMSE=0.9555, R²=0.7837, MAPE=27.20%\n",
      "Building model for WorkType: 214 Large orders\n",
      "  Model for 214 Large orders - MAE: 0.8231, RMSE: 1.2922, R²: 0.8209, MAPE: 25.76%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.9725, RMSE=1.6258, R²=0.7339, MAPE=27.29%\n",
      "    Fold 2: MAE=0.6857, RMSE=1.0883, R²=0.8542, MAPE=22.74%\n",
      "    Fold 3: MAE=0.7340, RMSE=1.0845, R²=0.8465, MAPE=24.26%\n",
      "    Fold 4: MAE=0.6619, RMSE=1.0374, R²=0.8540, MAPE=22.54%\n",
      "    Fold 5: MAE=1.0613, RMSE=1.6249, R²=0.8161, MAPE=31.98%\n",
      "Building model for WorkType: 215 Picking Online\n",
      "  Model for 215 Picking Online - MAE: 0.9452, RMSE: 1.5679, R²: 0.8409, MAPE: 25.85%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.9926, RMSE=1.7287, R²=0.8328, MAPE=26.00%\n",
      "    Fold 2: MAE=0.9784, RMSE=1.5523, R²=0.8386, MAPE=29.67%\n",
      "    Fold 3: MAE=0.8245, RMSE=1.2701, R²=0.8859, MAPE=23.30%\n",
      "    Fold 4: MAE=0.9633, RMSE=1.6085, R²=0.8219, MAPE=25.07%\n",
      "    Fold 5: MAE=0.9670, RMSE=1.6801, R²=0.8254, MAPE=25.23%\n",
      "Building model for WorkType: 216\n",
      "  Model for 216 - MAE: 0.3781, RMSE: 0.6784, R²: 0.5806, MAPE: 26.00%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.2834, RMSE=0.4517, R²=0.6359, MAPE=22.99%\n",
      "    Fold 2: MAE=0.2672, RMSE=0.5501, R²=0.6317, MAPE=18.81%\n",
      "    Fold 3: MAE=0.4441, RMSE=0.8288, R²=0.4464, MAPE=27.79%\n",
      "    Fold 4: MAE=0.4675, RMSE=0.8068, R²=0.5694, MAPE=30.92%\n",
      "    Fold 5: MAE=0.4283, RMSE=0.7546, R²=0.6194, MAPE=29.47%\n",
      "Building model for WorkType: 217 Returns\n",
      "  Model for 217 Returns - MAE: 0.6859, RMSE: 1.0855, R²: 0.8296, MAPE: 29.92%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.8506, RMSE=1.3830, R²=0.8522, MAPE=31.15%\n",
      "    Fold 2: MAE=0.7710, RMSE=1.2483, R²=0.8547, MAPE=30.97%\n",
      "    Fold 3: MAE=0.5404, RMSE=0.8488, R²=0.8280, MAPE=23.83%\n",
      "    Fold 4: MAE=0.6231, RMSE=0.9387, R²=0.8005, MAPE=33.27%\n",
      "    Fold 5: MAE=0.6443, RMSE=1.0089, R²=0.8128, MAPE=30.36%\n",
      "Building model for WorkType: 218\n",
      "  Model for 218 - MAE: 0.0479, RMSE: 0.2416, R²: 0.0422, MAPE: 2.46%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.0116, RMSE=0.0673, R²=0.0814, MAPE=1.16%\n",
      "    Fold 2: MAE=0.0167, RMSE=0.0848, R²=0.0416, MAPE=1.67%\n",
      "    Fold 3: MAE=0.0056, RMSE=0.0481, R²=-0.1105, MAPE=0.56%\n",
      "    Fold 4: MAE=0.0000, RMSE=0.0001, R²=-0.0022, MAPE=0.00%\n",
      "    Fold 5: MAE=0.2056, RMSE=1.0079, R²=0.2005, MAPE=8.93%\n",
      "Building model for WorkType: 219\n",
      "  Model for 219 - MAE: 0.0887, RMSE: 0.2899, R²: 0.2973, MAPE: 6.04%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.1853, RMSE=0.5008, R²=0.6724, MAPE=14.46%\n",
      "    Fold 2: MAE=0.1952, RMSE=0.6762, R²=0.6539, MAPE=9.42%\n",
      "    Fold 3: MAE=0.0063, RMSE=0.0425, R²=0.1950, MAPE=0.63%\n",
      "    Fold 4: MAE=0.0300, RMSE=0.1218, R²=-0.1392, MAPE=3.00%\n",
      "    Fold 5: MAE=0.0268, RMSE=0.1083, R²=0.1042, MAPE=2.68%\n",
      "Building model for WorkType: 220\n",
      "  Model for 220 - MAE: 0.0168, RMSE: 0.1069, R²: -508941.7445, MAPE: 1.58%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.0436, RMSE=0.1807, R²=-2544708.0093, MAPE=4.36%\n",
      "    Fold 2: MAE=0.0072, RMSE=0.0944, R²=-0.2018, MAPE=0.53%\n",
      "    Fold 3: MAE=0.0032, RMSE=0.0357, R²=0.3649, MAPE=0.32%\n",
      "    Fold 4: MAE=0.0042, RMSE=0.0539, R²=-0.4578, MAPE=0.42%\n",
      "    Fold 5: MAE=0.0261, RMSE=0.1698, R²=-0.4185, MAPE=2.29%\n",
      "Building model for WorkType: 221 Stocktaking\n",
      "  Model for 221 Stocktaking - MAE: 0.3329, RMSE: 0.5126, R²: 0.6736, MAPE: 25.01%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.4420, RMSE=0.6332, R²=0.7925, MAPE=29.22%\n",
      "    Fold 2: MAE=0.3435, RMSE=0.4939, R²=0.6655, MAPE=27.95%\n",
      "    Fold 3: MAE=0.3220, RMSE=0.4581, R²=0.6565, MAPE=24.33%\n",
      "    Fold 4: MAE=0.2668, RMSE=0.4004, R²=0.7089, MAPE=21.88%\n",
      "    Fold 5: MAE=0.2901, RMSE=0.5776, R²=0.5445, MAPE=21.66%\n",
      "Building model for WorkType: 222 Storage optimization\n",
      "  Model for 222 Storage optimization - MAE: 0.4074, RMSE: 1.1202, R²: 0.3697, MAPE: 28.47%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.6580, RMSE=3.3628, R²=0.0479, MAPE=31.55%\n",
      "    Fold 2: MAE=0.4405, RMSE=0.7018, R²=0.4874, MAPE=33.82%\n",
      "    Fold 3: MAE=0.3476, RMSE=0.6045, R²=0.3848, MAPE=27.24%\n",
      "    Fold 4: MAE=0.3555, RMSE=0.5393, R²=0.4640, MAPE=29.07%\n",
      "    Fold 5: MAE=0.2356, RMSE=0.3925, R²=0.4643, MAPE=20.69%\n",
      "Building model for WorkType: 223\n",
      "  Model for 223 - MAE: 0.4134, RMSE: 0.9652, R²: 0.3438, MAPE: 28.47%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.3413, RMSE=0.7030, R²=0.4249, MAPE=24.88%\n",
      "    Fold 2: MAE=0.4503, RMSE=1.5314, R²=0.1894, MAPE=26.75%\n",
      "    Fold 3: MAE=0.1708, RMSE=0.4127, R²=0.3265, MAPE=14.07%\n",
      "    Fold 4: MAE=0.5429, RMSE=1.1130, R²=0.3580, MAPE=37.28%\n",
      "    Fold 5: MAE=0.5618, RMSE=1.0660, R²=0.4200, MAPE=39.35%\n",
      "Building model for WorkType: 224\n",
      "  Model for 224 - MAE: 0.1174, RMSE: 0.5422, R²: 0.2086, MAPE: 8.53%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.0495, RMSE=0.1238, R²=0.2288, MAPE=4.78%\n",
      "    Fold 2: MAE=0.0387, RMSE=0.1162, R²=0.2289, MAPE=3.77%\n",
      "    Fold 3: MAE=0.0889, RMSE=0.2025, R²=0.2239, MAPE=8.35%\n",
      "    Fold 4: MAE=0.1619, RMSE=1.3908, R²=0.0633, MAPE=9.71%\n",
      "    Fold 5: MAE=0.2482, RMSE=0.8775, R²=0.2982, MAPE=16.02%\n",
      "Building model for WorkType: 225\n",
      "  Model for 225 - MAE: 0.0150, RMSE: 0.0697, R²: 0.1214, MAPE: 1.47%\n",
      "  Cross-validation details:\n",
      "    Fold 1: MAE=0.0371, RMSE=0.1233, R²=0.4681, MAPE=3.71%\n",
      "    Fold 2: MAE=0.0054, RMSE=0.0420, R²=0.3559, MAPE=0.54%\n",
      "    Fold 3: MAE=0.0024, RMSE=0.0150, R²=-0.4521, MAPE=0.24%\n",
      "    Fold 4: MAE=0.0259, RMSE=0.1388, R²=0.3904, MAPE=2.40%\n",
      "    Fold 5: MAE=0.0045, RMSE=0.0294, R²=-0.1555, MAPE=0.45%\n",
      "Saving model files...\n",
      "Successfully saved 25 models!\n"
     ]
    }
   ],
   "source": [
    " # Get list of unique WorkTypes\n",
    "work_types = lag_features_df['WorkType'].unique()\n",
    "models, feature_importances, metrics = build_models(lag_features_df, work_types, n_splits=5)\n",
    "\n",
    "# Save models, feature importances, and metrics to files\n",
    "print(\"Saving model files...\")\n",
    "with open(os.path.join(\"models\", \"work_utilization_models.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(models, f)\n",
    "    \n",
    "with open(os.path.join(\"models\", \"work_utilization_feature_importances.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(feature_importances, f)\n",
    "    \n",
    "with open(os.path.join(\"models\", \"work_utilization_metrics.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(metrics, f)\n",
    "    \n",
    "print(f\"Successfully saved {len(models)} models!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
